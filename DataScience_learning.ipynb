{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sneymz00/learn_IA/blob/main/DataScience_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header-title"
      },
      "source": [
        "# üìä Recordatorios Data Science - Python & Pandas\n",
        "\n",
        "**Apuntes r√°pidos para limpieza y an√°lisis de datos**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imports-section"
      },
      "source": [
        "## üõ†Ô∏è Imports B√°sicos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports-code"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Para mounting Google Drive (si necesario)\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exploration-section"
      },
      "source": [
        "## üîç 1. Exploraci√≥n Inicial de Datos\n",
        "\n",
        "**Comandos esenciales para conocer tu dataset:**\n",
        "\n",
        "```python\n",
        "# Cargar datos\n",
        "df = pd.read_csv('archivo.csv')  # o pd.read_csv('archivo.csv', sep=';')\n",
        "\n",
        "# Exploraci√≥n b√°sica\n",
        "df.head()           # Primeras 5 filas\n",
        "df.tail()           # √öltimas 5 filas\n",
        "df.shape            # (filas, columnas)\n",
        "df.columns          # Nombres de columnas\n",
        "df.dtypes           # Tipos de datos\n",
        "df.info()           # Resumen completo\n",
        "df.describe()       # Estad√≠sticas descriptivas\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cleaning-section"
      },
      "source": [
        "## üßπ 2. Limpieza de Datos\n",
        "\n",
        "### **Valores Nulos**\n",
        "```python\n",
        "# Detectar nulos\n",
        "df.isnull().sum()                    # Conteo por columna\n",
        "df.isnull().sum() / len(df) * 100   # Porcentaje\n",
        "\n",
        "# Tratar nulos\n",
        "df.dropna()                         # Eliminar filas con nulos\n",
        "df.fillna(0)                        # Rellenar con 0\n",
        "df.fillna(df.mean())                # Rellenar con media\n",
        "df.fillna(df.mode()[0])             # Rellenar con moda\n",
        "```\n",
        "\n",
        "### **Duplicados**\n",
        "```python\n",
        "# Detectar y eliminar duplicados\n",
        "df.duplicated().sum()               # Contar duplicados\n",
        "df.drop_duplicates()                # Eliminar duplicados\n",
        "```\n",
        "\n",
        "### **Normalizaci√≥n de Texto**\n",
        "```python\n",
        "# Limpiar texto\n",
        "df['columna'] = df['columna'].str.strip()      # Quitar espacios\n",
        "df['columna'] = df['columna'].str.lower()      # Min√∫sculas\n",
        "df['columna'] = df['columna'].str.title()      # Formato T√≠tulo\n",
        "df['columna'] = df['columna'].str.upper()      # May√∫sculas\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "outliers-section"
      },
      "source": [
        "## üéØ 3. Detecci√≥n de Outliers - M√©todo IQR\n",
        "\n",
        "**F√≥rmula IQR (Rango Intercuart√≠lico):**\n",
        "- Q1 = Percentil 25\n",
        "- Q3 = Percentil 75  \n",
        "- IQR = Q3 - Q1\n",
        "- L√≠mite inferior = Q1 - 1.5 √ó IQR\n",
        "- L√≠mite superior = Q3 + 1.5 √ó IQR\n",
        "\n",
        "**C√≥digo:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "outliers-code"
      },
      "outputs": [],
      "source": [
        "def detectar_outliers_iqr(df, columna):\n",
        "    \"\"\"\n",
        "    Detecta outliers usando m√©todo IQR\n",
        "    \"\"\"\n",
        "    # Calcular cuartiles\n",
        "    Q1 = df[columna].quantile(0.25)\n",
        "    Q3 = df[columna].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    # Definir l√≠mites\n",
        "    limite_inferior = Q1 - 1.5 * IQR\n",
        "    limite_superior = Q3 + 1.5 * IQR\n",
        "\n",
        "    # Identificar outliers\n",
        "    outliers = df[(df[columna] < limite_inferior) |\n",
        "                  (df[columna] > limite_superior)]\n",
        "\n",
        "    print(f\"Q1: {Q1:.2f}\")\n",
        "    print(f\"Q3: {Q3:.2f}\")\n",
        "    print(f\"IQR: {IQR:.2f}\")\n",
        "    print(f\"L√≠mites: [{limite_inferior:.2f}, {limite_superior:.2f}]\")\n",
        "    print(f\"Outliers encontrados: {len(outliers)}\")\n",
        "\n",
        "    return outliers, limite_inferior, limite_superior"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "filtering-section"
      },
      "source": [
        "## üîé 4. Filtrado de Datos (WHERE)\n",
        "\n",
        "**Filtros b√°sicos:**\n",
        "```python\n",
        "# Filtros simples\n",
        "df[df['columna'] > 50]              # Mayor que\n",
        "df[df['columna'] == 'valor']        # Igual a\n",
        "df[df['columna'].isin(['A', 'B'])]  # Est√° en lista\n",
        "\n",
        "# Filtros m√∫ltiples\n",
        "df[(df['col1'] > 10) & (df['col2'] == 'texto')]    # AND\n",
        "df[(df['col1'] > 10) | (df['col2'] == 'texto')]    # OR\n",
        "df[~(df['columna'] > 10)]                          # NOT\n",
        "\n",
        "# M√©todo query (alternativa)\n",
        "df.query('columna > 50')\n",
        "df.query('col1 > 10 and col2 == \"texto\"')\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "groupby-section"
      },
      "source": [
        "## üìä 5. Agrupaci√≥n y Agregaci√≥n (GroupBy)\n",
        "\n",
        "```python\n",
        "# Agrupaci√≥n b√°sica\n",
        "df.groupby('columna').mean()                    # Media por grupo\n",
        "df.groupby('columna').sum()                     # Suma por grupo\n",
        "df.groupby('columna').count()                   # Conteo por grupo\n",
        "\n",
        "# M√∫ltiples agregaciones\n",
        "df.groupby('columna').agg({\n",
        "    'col1': 'mean',\n",
        "    'col2': 'sum',\n",
        "    'col3': 'count'\n",
        "})\n",
        "\n",
        "# M√∫ltiples columnas de agrupaci√≥n\n",
        "df.groupby(['col1', 'col2']).mean()\n",
        "\n",
        "# Ordenar resultados\n",
        "df.groupby('columna').sum().sort_values('col1', ascending=False)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "datatypes-section"
      },
      "source": [
        "## üîß 6. Conversi√≥n de Tipos de Datos\n",
        "\n",
        "```python\n",
        "# Conversiones b√°sicas\n",
        "df['columna'] = df['columna'].astype('int')        # A entero\n",
        "df['columna'] = df['columna'].astype('float')      # A decimal\n",
        "df['columna'] = df['columna'].astype('str')        # A texto\n",
        "df['columna'] = df['columna'].astype('category')   # A categor√≠a\n",
        "\n",
        "# Conversiones especiales\n",
        "df['fecha'] = pd.to_datetime(df['fecha'])          # A fecha\n",
        "df['numero'] = pd.to_numeric(df['numero'], errors='coerce')  # A num√©rico\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tips-section"
      },
      "source": [
        "## üí° 7. Tips y Trucos R√°pidos\n",
        "\n",
        "### **Crear nuevas columnas**\n",
        "```python\n",
        "# Columna condicional\n",
        "df['nueva_col'] = np.where(df['col'] > 50, 'Alto', 'Bajo')\n",
        "\n",
        "# Columna desde otra\n",
        "df['nueva_col'] = df['col1'] * df['col2']\n",
        "\n",
        "# Columna binaria (0/1)\n",
        "df['tiene_valor'] = (df['columna'].notnull()).astype(int)\n",
        "```\n",
        "\n",
        "### **Conteos y frecuencias**\n",
        "```python\n",
        "df['columna'].value_counts()           # Conteo de valores √∫nicos\n",
        "df['columna'].value_counts(normalize=True)  # Porcentajes\n",
        "df['columna'].nunique()                # N√∫mero de valores √∫nicos\n",
        "```\n",
        "\n",
        "### **Ordenamiento**\n",
        "```python\n",
        "df.sort_values('columna', ascending=False)      # Descendente\n",
        "df.sort_values(['col1', 'col2'])                # M√∫ltiples columnas\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "workflow-section"
      },
      "source": [
        "## üîÑ 8. Flujo de Trabajo Recomendado\n",
        "\n",
        "### **Secuencia t√≠pica de limpieza:**\n",
        "\n",
        "1. **Cargar** ‚Üí `pd.read_csv()`\n",
        "2. **Explorar** ‚Üí `df.info()`, `df.describe()`\n",
        "3. **Detectar problemas** ‚Üí nulos, duplicados, outliers\n",
        "4. **Limpiar** ‚Üí eliminar/imputar seg√∫n criterio\n",
        "5. **Normalizar** ‚Üí tipos de datos, texto\n",
        "6. **Verificar** ‚Üí confirmar limpieza exitosa\n",
        "7. **Analizar** ‚Üí groupby, filtros, agregaciones\n",
        "8. **Guardar** ‚Üí `df.to_csv('limpio.csv', index=False)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "checklist-section"
      },
      "source": [
        "## 9. Checklist Final\n",
        "\n",
        "**Antes de analizar, verificar:**\n",
        "\n",
        "- [ ] **Sin valores nulos** ‚Üí `df.isnull().sum().sum() == 0`\n",
        "- [ ] **Sin duplicados** ‚Üí `df.duplicated().sum() == 0`\n",
        "- [ ] **Tipos correctos** ‚Üí `df.dtypes`\n",
        "- [ ] **Outliers tratados** ‚Üí m√©todo IQR aplicado\n",
        "- [ ] **Texto normalizado** ‚Üí may√∫sculas/min√∫sculas consistentes\n",
        "- [ ] **Fechas convertidas** ‚Üí `pd.to_datetime()` si aplica\n",
        "\n",
        "**Comando de verificaci√≥n r√°pida:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "verification-code"
      },
      "outputs": [],
      "source": [
        "def verificar_limpieza(df):\n",
        "    \"\"\"\n",
        "    Verifica que el dataset est√© limpio\n",
        "    \"\"\"\n",
        "    print(\"üîç VERIFICACI√ìN DE LIMPIEZA\")\n",
        "    print(\"=\" * 30)\n",
        "    print(f\"üìã Dimensiones: {df.shape}\")\n",
        "    print(f\"‚ùå Valores nulos: {df.isnull().sum().sum()}\")\n",
        "    print(f\"üîÑ Duplicados: {df.duplicated().sum()}\")\n",
        "    print(f\"üìä Tipos de datos:\")\n",
        "    print(df.dtypes.value_counts())\n",
        "\n",
        "    if df.isnull().sum().sum() == 0 and df.duplicated().sum() == 0:\n",
        "        print(\"\\n‚úÖ Dataset limpio - Listo para an√°lisis\")\n",
        "    else:\n",
        "        print(\"\\n‚ö†Ô∏è Dataset necesita m√°s limpieza\")\n",
        "\n",
        "# Usar as√≠: verificar_limpieza(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "footer-section"
      },
      "source": [
        "---\n",
        "\n",
        "## üéì Recordatorio Final\n",
        "\n",
        "> **\"Los datos limpios son la base de cualquier an√°lisis exitoso\"**\n",
        "\n",
        "**Regla de oro:** Siempre explorar antes de limpiar, y verificar despu√©s de limpiar.\n",
        "\n",
        "**Pr√≥ximos pasos:** Una vez limpios los datos ‚Üí visualizaci√≥n, modelado, insights.\n",
        "\n",
        "---\n",
        "*Apuntes creados para Data Science*"
      ]
    }
  ]
}